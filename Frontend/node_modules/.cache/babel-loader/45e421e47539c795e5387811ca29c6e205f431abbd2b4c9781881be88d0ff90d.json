{"ast":null,"code":"import Header from\"../../components/Header\";import\"./About.css\";import najibPicture from\"../../headshots/Haidar_Najib_headshot.jpeg\";import aaronPicture from\"../../headshots/Hong_Aaron_headshot.jpeg\";import akashPicture from\"../../headshots/Shetty_Akash_headshot.png\";import ichiroPicture from\"../../headshots/Nakata_Gerald_headshot.jpeg\";import benjaminPicture from\"../../headshots/Jiang_Benjamin_headshot.jpeg\";import whitneyPicture from\"../../headshots/Waldinger_Whitney_headshot.jpeg\";import joniPicture from\"../../headshots/Nguyen_Joni_headshot.jpeg\";import brianPicture from\"../../headshots/Han_Brian_headshot.jpeg\";import{jsx as _jsx,jsxs as _jsxs}from\"react/jsx-runtime\";export default function About(){return/*#__PURE__*/_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"div\",{children:/*#__PURE__*/_jsx(Header,{})}),/*#__PURE__*/_jsxs(\"div\",{className:\"container\",children:[/*#__PURE__*/_jsx(\"h1\",{className:\"heading1\",children:\"About\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"The Alaska Center for Energy and Power (ACEP) has initiated a project titled \\\"Efficient Energy Research: Building an Advanced Language Model and Interface\\\" with the objective of developing an advanced Language Model (LLM) Chatbot tailored specifically to the field of energy research. Over a dedicated period of three months, the ACEP team has focused their efforts on designing and implementing this innovative solution aimed at revolutionizing the process of data discovery for energy researchers.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"The project's scope encompasses the development and deployment of the LLM Chatbot, which is intended to streamline data discovery from dense academic works. By harnessing open-source technology, the Chatbot will enable researchers at the University of Alaska to access relevant information and citations efficiently, thus addressing the challenge of data discovery in energy research.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Recognizing the significant time and effort researchers invest in searching for relevant materials, the initiative aims to alleviate this burden by providing a user-friendly interface for prompt and accurate information retrieval. Moreover, the project aspires to extend its impact beyond the University of Alaska by evolving into an open-source solution that benefits multiple universities or even multiple different industries.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Through fostering collaborative knowledge sharing, the project seeks to advance research endeavors in the field of energy. The ACEP team's ultimate goal is to contribute to the enhancement of energy research efficiency and effectiveness, thereby driving advancements and addressing critical energy-related challenges.\"}),/*#__PURE__*/_jsx(\"h1\",{className:\"heading1\",children:\"Team Overview\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Introducing our exceptional team, comprised of driven individuals with a shared passion for excellence. With diverse backgrounds and expertise, we unite under a common goal, leveraging our unique strengths to achieve remarkable results together.\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Najib\",src:najibPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Najib Haidar\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Najib is part of the backend team and has had a part in all aspects of it. Initially, he spearheaded the creation of the initial OCR pipeline. To elaborate, he tested and deployed Google's DocumentAI and FormParser for text and table extraction respectfully. After making these processes work locally, he shifted them into a single pipeline function call that would allow this process to work remotely over Google Drive, whereby the 3 storage buckets were created. In addition to the OCR pipeline, he worked with Whitney and Akash in allowing the LLM respond with the sources from which it is pulling the information and link it to the corresponding PDFs. Najib also worked with Ichiro on creating a web scraper that could extract PDFs from web pages and download them locally, saving plenty of time. This webscraper was later expanded by Najib to extract the PDFs from the ISER dataset that was provided by Dhaha. In addition, Najib worked with Ben and Aaron on details with the connector such as Zapier and AirByte and later sat down with Ben and figured out how autonomously extract metadata from PDFs using their corresponding DOI.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Aaron\",src:aaronPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Aaron Hong\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Aaron is part of the backend team. He was responsible for the design and implementation of the now obsolete Airbyte data pipeline, as well as the decision to use Google Drive as the main form of pipeline cloud storage. He conducted extensive research on ways to automatically transfer data across services and developed an early data pipeline prototype using Airbyte. Using his deployments of Airbyte and Elasticsearch, documents processed by the OCR pipeline were sent to a user endpoint for the first time ever. When the backend design iterated past using Airbyte and Elasticsearch, Aaron worked with the rest of the backend team to refine the new entirely Pythonic data pipeline. In specific, he worked with Najib on his OCR pipeline to refine the JSON output of Google\\u2019s DocumentAI, leading to a 99% reduction in JSON file size with negligible loss of information.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Akash\",src:akashPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Akash Shetty\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Akash is part of the backend team for the ACEP Captstone team. In his role contributing to the design of ACEP, Akash had the unique opportunity to bridge the realms of both frontend and backend development, for a cohesive user experience. His main accomplishment was spearheading the creation of the actual chatbot, a task that combined the efforts of creating the processed data and creating a RAG model using MILVUS as his vector database, an embedding model from Hugging face, and the underlying LLM using OPENAI gpt-3.5-turbo. Collaborating closely with the backend team, Akash contributed to the robust architecture that underpins the chatbot's functionality, ensuring reliability, scalability, and performance. This holistic approach enabled him to ensure that the chatbot not only meets the immediate needs of users but also integrates smoothly with the backend systems, laying a foundation for future enhancements and features. Throughout the project Akash was able to collaborate and develop with both the front and backend team.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Ichiro\",src:ichiroPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Ichiro (Gerald) Nakata\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Ichiro is the project manager for the ACEP Capstone team. He organized backend group meetings and documentation as well as organizing overall group meetings. In addition, he helped to update and maintain the internal documentation for the team. This included creating graphics as needed for the team pertaining to the overall project structure, the backend project structure, as well as the Gantt chart. All biweekly reports were also his responsibility, alongside setting up documents for the weekly individual and group reports for the faculty/TA meetings. Additionally, he contributed to the start of the backend PDF pipeline with a web scraper that was used to pull PDFs from websites. The scraper pulls the HTML and parses through the REGEX to find all of the links to documents and subsequently downloads them.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Benjamin\",src:benjaminPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Benjamin Jiang\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Benjamin is part of the backend team, notably in data management and processing. His contributions include advocating for the adoption of Google Drive for its cost-effectiveness and flexibility, enhancing data manipulation methods, and recommending Amazon Textract for superior table parsing performance over Google Form Parser. He spearheaded the design and implementation of a data pipeline that facilitated seamless data transfers between cloud storage and Elasticsearch, incorporating research into solutions like Meltano, Airbyte, and Zapier for effective data integration. With the shift towards using a vector database, now the effort has been transferred to calling Milvus api using python code. Furthermore, in collaboration with team members Nijib and Aaron, he improved metadata acquisition and refined JSON outputs from Document AI OCR, contributing to the quality of document processing. Currently, he's focused on refining Python-based data pipelines alongside the backend team, aiming to bolster our data processing capabilities and ensure the scalability of our backend infrastructure. \"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Whitney\",src:whitneyPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Whitney Waldinger\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Whitney is the communication manager for the ACEP Capstone team. She handled the communication between Rose Johnson (TA), Rajesh Subramayan (Faculty Mentor), Dhaha Nur (Industry Mentor) and the rest of the capstone team. This included helping to schedule weekly meetings and reserving meeting locations. She also acted as the project manager for the frontend team. She helped to create, design, code, and improve the UI. She worked with Dhaha and iterated through various different designs for the frontend. At first, she implemented an App Search utilizing Elasticsearch. She created a Search Engine in the Elastic Cloud to do so. This UI allowed the users to filter the search results and returned a list of all documents fitting the criteria. Then, once the team chose to focus on a Chatbot integration rather than search engine, she helped to alter Akash\\u2019s chatbot UI to fit the design guidelines set by Dhaha. She also worked with Najib and Akash to incorporate not only the summarized answer but also the data sources, with links, under each response from the LLM.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Joni\",src:joniPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Joni Nguyen\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Joni is the budget manager for the ACEP Capstone team. She is responsible for overseeing project budget, and communicating with the team and mentors about necessary purchases. Currently, there are no purchases that need to be made but if there are, she is the point of contact for all things finance for this team. Joni is also a part of the frontend team for the ACEP Capstone team. Her primary responsibilities include collaborating and communicating with the frontend team and the rest of the ACEP team, and implementing the static website. To develop the user interface (UI), Joni used the React.js framework to implement the various components and pages. With Dhaha\\u2019s guidance and direction, Joni, alongside the rest of the frontend team, curated the website\\u2019s design, layout, and style. Furthermore, Joni took charge of documenting the UI by outlining its structure, component functionalities, and usage guidelines. This documentation encompasses detailed descriptions of each component, their functions, and how they interact with one another. Additionally, Joni documented the project's setup instructions, coding conventions, and best practices, ensuring clarity and consistency in the development process.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-container\",children:[/*#__PURE__*/_jsx(\"div\",{className:\"flex-img\",children:/*#__PURE__*/_jsx(\"img\",{alt:\"Brian\",src:brianPicture})}),/*#__PURE__*/_jsxs(\"div\",{className:\"flex-text\",children:[/*#__PURE__*/_jsx(\"h2\",{className:\"heading2\",children:\"Brian Han\"}),/*#__PURE__*/_jsx(\"p\",{className:\"paragraph\",children:\"Brian is part of the frontend team for the ACEP Capstone team, primarily responsible for the implementation of the static websites. In the development process, he utilized the React.js framework to write robust code for various components and pages. Concurrently, Brian collaborated with Whitney and Joni to discuss and design the webpage\\u2019s layouts, styles, and distribution of pages, as per Daha's specifications. Based on these requirements, Brian has programmed the CSS styles for several components and improved the functionality of the search bar and chat box. Importantly, Brian also manages the codebase and architecture of the front-end project. Leveraging the component-based philosophy of the React framework, he has outlined the project workspace, breaking down the front-end implementation into discrete components and further refining the page layout hierarchy. This approach decouples individual code contributions, preventing unnecessary conflicts. Moreover, Brian has written the routes for the project, enabling navigation between different pages. This facilitates the addition of more pages and routings, providing a seamless development workflow for future expansions.\"})]})]})]}),/*#__PURE__*/_jsx(\"div\",{className:\"whiteSpace\"})]});};","map":{"version":3,"names":["Header","najibPicture","aaronPicture","akashPicture","ichiroPicture","benjaminPicture","whitneyPicture","joniPicture","brianPicture","jsx","_jsx","jsxs","_jsxs","About","children","className","alt","src"],"sources":["/Users/whitneywaldinger/capstone-repo/acep-energy-llm/Frontend/src/pages/about/About.tsx"],"sourcesContent":["import Header from \"../../components/Header\";\nimport \"./About.css\";\nimport najibPicture from \"../../headshots/Haidar_Najib_headshot.jpeg\"\nimport aaronPicture from \"../../headshots/Hong_Aaron_headshot.jpeg\"\nimport akashPicture from \"../../headshots/Shetty_Akash_headshot.png\"\nimport ichiroPicture from \"../../headshots/Nakata_Gerald_headshot.jpeg\"\nimport benjaminPicture from \"../../headshots/Jiang_Benjamin_headshot.jpeg\"\nimport whitneyPicture from \"../../headshots/Waldinger_Whitney_headshot.jpeg\"\nimport joniPicture from \"../../headshots/Nguyen_Joni_headshot.jpeg\"\nimport brianPicture from \"../../headshots/Han_Brian_headshot.jpeg\"\n\n\nexport default function About() {\n  return (\n    <div>\n      <div>\n        <Header />\n      </div>\n      <div className=\"container\">\n        <h1 className=\"heading1\">About</h1>\n        <p className=\"paragraph\">The Alaska Center for Energy and Power (ACEP) has initiated a project\n        titled \"Efficient Energy Research: Building an Advanced Language Model and Interface\" with the\n        objective of developing an advanced Language Model (LLM) Chatbot tailored specifically to the\n        field of energy research. Over a dedicated period of three months, the ACEP team has focused\n        their efforts on designing and implementing this innovative solution aimed at revolutionizing\n        the process of data discovery for energy researchers.</p>\n        <p className=\"paragraph\">The project's scope encompasses the development and deployment of the\n        LLM Chatbot, which is intended to streamline data discovery from dense academic works.\n        By harnessing open-source technology, the Chatbot will enable researchers at the University\n        of Alaska to access relevant information and citations efficiently, thus addressing the challenge\n        of data discovery in energy research.</p>\n        <p className=\"paragraph\">Recognizing the significant time and effort researchers invest in searching\n        for relevant materials, the initiative aims to alleviate this burden by providing a user-friendly\n        interface for prompt and accurate information retrieval. Moreover, the project aspires to extend\n        its impact beyond the University of Alaska by evolving into an open-source solution that benefits\n        multiple universities or even multiple different industries.</p>\n        <p className=\"paragraph\">Through fostering collaborative knowledge sharing, the project seeks to\n        advance research endeavors in the field of energy. The ACEP team's ultimate goal is to contribute\n        to the enhancement of energy research efficiency and effectiveness, thereby driving advancements\n        and addressing critical energy-related challenges.</p>\n\n        <h1 className=\"heading1\">Team Overview</h1>\n        <p className=\"paragraph\">Introducing our exceptional team, comprised of driven individuals with\n        a shared passion for excellence. With diverse backgrounds and expertise, we unite under a common\n        goal, leveraging our unique strengths to achieve remarkable results together.</p>\n\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Najib\" src={najibPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Najib Haidar</h2>\n            <p className=\"paragraph\">Najib is part of the backend team and has had a part in all aspects\n            of it. Initially, he spearheaded the creation of the initial OCR pipeline. To elaborate, he\n            tested and deployed Google's DocumentAI and FormParser for text and table extraction respectfully.\n            After making these processes work locally, he shifted them into a single pipeline function call\n            that would allow this process to work remotely over Google Drive, whereby the 3 storage buckets\n            were created. In addition to the OCR pipeline, he worked with Whitney and Akash in allowing the\n            LLM respond with the sources from which it is pulling the information and link it to the\n            corresponding PDFs. Najib also worked with Ichiro on creating a web scraper that could extract\n            PDFs from web pages and download them locally, saving plenty of time. This webscraper was\n            later expanded by Najib to extract the PDFs from the ISER dataset that was provided by Dhaha.\n            In addition, Najib worked with Ben and Aaron on details with the connector such as Zapier and\n            AirByte and later sat down with Ben and figured out how autonomously extract metadata from PDFs\n            using their corresponding DOI.</p>\n          </div>\n        </div>\n\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Aaron\" src={aaronPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Aaron Hong</h2>\n            <p className=\"paragraph\">Aaron is part of the backend team. He was responsible for the design\n            and implementation of the now obsolete Airbyte data pipeline, as well as the decision to use\n            Google Drive as the main form of pipeline cloud storage. He conducted extensive research on\n            ways to automatically transfer data across services and developed an early data pipeline prototype\n            using Airbyte. Using his deployments of Airbyte and Elasticsearch, documents processed by the OCR\n            pipeline were sent to a user endpoint for the first time ever. When the backend design iterated\n            past using Airbyte and Elasticsearch, Aaron worked with the rest of the backend team to refine\n            the new entirely Pythonic data pipeline. In specific, he worked with Najib on his OCR pipeline\n            to refine the JSON output of Google’s DocumentAI, leading to a 99% reduction in JSON file size\n            with negligible loss of information.</p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Akash\" src={akashPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Akash Shetty</h2>\n            <p className=\"paragraph\">Akash is part of the backend team for the ACEP Captstone team. In his\n            role contributing to the design of ACEP, Akash had the unique opportunity to bridge the realms\n            of both frontend and backend development, for a cohesive user experience. His main accomplishment\n            was spearheading the creation of the actual chatbot, a task that combined the efforts of creating\n            the processed data and creating a RAG model using MILVUS as his vector database, an embedding\n            model from Hugging face, and the underlying LLM using OPENAI gpt-3.5-turbo. Collaborating closely\n            with the backend team, Akash contributed to the robust architecture that underpins the chatbot's\n            functionality, ensuring reliability, scalability, and performance. This holistic approach enabled\n            him to ensure that the chatbot not only meets the immediate needs of users but also integrates\n            smoothly with the backend systems, laying a foundation for future enhancements and features. Throughout\n            the project Akash was able to collaborate and develop with both the front and backend team.</p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Ichiro\" src={ichiroPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Ichiro (Gerald) Nakata</h2>\n            <p className=\"paragraph\">Ichiro is the project manager for the ACEP Capstone team. He organized\n            backend group meetings and documentation as well as organizing overall group meetings. In addition,\n            he helped to update and maintain the internal documentation for the team. This included creating\n            graphics as needed for the team pertaining to the overall project structure, the backend project\n            structure, as well as the Gantt chart. All biweekly reports were also his responsibility, alongside\n            setting up documents for the weekly individual and group reports for the faculty/TA meetings.\n            Additionally, he contributed to the start of the backend PDF pipeline with a web scraper that\n            was used to pull PDFs from websites. The scraper pulls the HTML and parses through the REGEX to\n            find all of the links to documents and subsequently downloads them.</p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Benjamin\" src={benjaminPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Benjamin Jiang</h2>\n            <p className=\"paragraph\">Benjamin is part of the backend team, notably in data management and\n            processing. His contributions include advocating for the adoption of Google Drive for its\n            cost-effectiveness and flexibility, enhancing data manipulation methods, and recommending\n            Amazon Textract for superior table parsing performance over Google Form Parser. He spearheaded\n            the design and implementation of a data pipeline that facilitated seamless data transfers\n            between cloud storage and Elasticsearch, incorporating research into solutions like Meltano,\n            Airbyte, and Zapier for effective data integration. With the shift towards using a vector\n            database, now the effort has been transferred to calling Milvus api using python code. Furthermore,\n            in collaboration with team members Nijib and Aaron, he improved metadata acquisition and refined\n            JSON outputs from Document AI OCR, contributing to the quality of document processing. Currently,\n            he's focused on refining Python-based data pipelines alongside the backend team, aiming to bolster\n            our data processing capabilities and ensure the scalability of our backend infrastructure. </p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Whitney\" src={whitneyPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Whitney Waldinger</h2>\n            <p className=\"paragraph\">Whitney is the communication manager for the ACEP Capstone team. She\n            handled the communication between Rose Johnson (TA), Rajesh Subramayan (Faculty Mentor), Dhaha\n            Nur (Industry Mentor) and the rest of the capstone team. This included helping to schedule weekly\n            meetings and reserving meeting locations. She also acted as the project manager for the frontend\n            team. She helped to create, design, code, and improve the UI. She worked with Dhaha and iterated\n            through various different designs for the frontend. At first, she implemented an App Search\n            utilizing Elasticsearch. She created a Search Engine in the Elastic Cloud to do so. This UI\n            allowed the users to filter the search results and returned a list of all documents fitting\n            the criteria. Then, once the team chose to focus on a Chatbot integration rather than search\n            engine, she helped to alter Akash’s chatbot UI to fit the design guidelines set by Dhaha. She\n            also worked with Najib and Akash to incorporate not only the summarized answer but also the\n            data sources, with links, under each response from the LLM.</p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Joni\" src={joniPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Joni Nguyen</h2>\n            <p className=\"paragraph\">Joni is the budget manager for the ACEP Capstone team. She is responsible for\n            overseeing project budget, and communicating with the team and mentors about necessary purchases.\n            Currently, there are no purchases that need to be made but if there are, she is the point of contact\n            for all things finance for this team. Joni is also a part of the frontend team for the ACEP Capstone\n            team. Her primary responsibilities include collaborating and communicating with the frontend team and\n            the rest of the ACEP team, and implementing the static website. To develop the user interface (UI),\n            Joni used the React.js framework to implement the various components and pages. With Dhaha’s guidance\n            and direction, Joni, alongside the rest of the frontend team, curated the website’s design, layout,\n            and style. Furthermore, Joni took charge of documenting the UI by outlining its structure, component\n            functionalities, and usage guidelines. This documentation encompasses detailed descriptions of each\n            component, their functions, and how they interact with one another. Additionally, Joni documented the\n            project's setup instructions, coding conventions, and best practices, ensuring clarity and consistency\n            in the development process.</p>\n          </div>\n        </div>\n\n        <div className=\"flex-container\">\n          <div className=\"flex-img\">\n            <img alt=\"Brian\" src={brianPicture} />\n          </div>\n          <div className=\"flex-text\">\n            <h2 className=\"heading2\">Brian Han</h2>\n            <p className=\"paragraph\">Brian is part of the frontend team for the ACEP Capstone team, primarily\n            responsible for the implementation of the static websites. In the development process, he utilized\n            the React.js framework to write robust code for various components and pages. Concurrently, Brian\n            collaborated with Whitney and Joni to discuss and design the webpage’s layouts, styles, and\n            distribution of pages, as per Daha's specifications. Based on these requirements, Brian has\n            programmed the CSS styles for several components and improved the functionality of the search bar\n            and chat box. Importantly, Brian also manages the codebase and architecture of the front-end project.\n            Leveraging the component-based philosophy of the React framework, he has outlined the project workspace,\n            breaking down the front-end implementation into discrete components and further refining the page layout\n            hierarchy. This approach decouples individual code contributions, preventing unnecessary conflicts. Moreover,\n            Brian has written the routes for the project, enabling navigation between different pages. This facilitates\n            the addition of more pages and routings, providing a seamless development workflow for future expansions.</p>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"whiteSpace\"></div>\n    </div>\n  );\n};"],"mappings":"AAAA,MAAO,CAAAA,MAAM,KAAM,yBAAyB,CAC5C,MAAO,aAAa,CACpB,MAAO,CAAAC,YAAY,KAAM,4CAA4C,CACrE,MAAO,CAAAC,YAAY,KAAM,0CAA0C,CACnE,MAAO,CAAAC,YAAY,KAAM,2CAA2C,CACpE,MAAO,CAAAC,aAAa,KAAM,6CAA6C,CACvE,MAAO,CAAAC,eAAe,KAAM,8CAA8C,CAC1E,MAAO,CAAAC,cAAc,KAAM,iDAAiD,CAC5E,MAAO,CAAAC,WAAW,KAAM,2CAA2C,CACnE,MAAO,CAAAC,YAAY,KAAM,yCAAyC,QAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,yBAGlE,cAAe,SAAS,CAAAC,KAAKA,CAAA,CAAG,CAC9B,mBACED,KAAA,QAAAE,QAAA,eACEJ,IAAA,QAAAI,QAAA,cACEJ,IAAA,CAACV,MAAM,GAAE,CAAC,CACP,CAAC,cACNY,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,OAAK,CAAI,CAAC,cACnCJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,ufAK4B,CAAG,CAAC,cACzDJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,kYAIY,CAAG,CAAC,cACzCJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,+aAImC,CAAG,CAAC,cAChEJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,+TAGyB,CAAG,CAAC,cAEtDJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,eAAa,CAAI,CAAC,cAC3CJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,uPAEoD,CAAG,CAAC,cAGjFF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,OAAO,CAACC,GAAG,CAAEhB,YAAa,CAAE,CAAC,CACnC,CAAC,cACNW,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,cAAY,CAAI,CAAC,cAC1CJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,inCAYK,CAAG,CAAC,EAC/B,CAAC,EACH,CAAC,cAGNF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,OAAO,CAACC,GAAG,CAAEf,YAAa,CAAE,CAAC,CACnC,CAAC,cACNU,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,YAAU,CAAI,CAAC,cACxCJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,22BASW,CAAG,CAAC,EACrC,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,OAAO,CAACC,GAAG,CAAEd,YAAa,CAAE,CAAC,CACnC,CAAC,cACNS,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,cAAY,CAAI,CAAC,cAC1CJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,ghCAUkE,CAAG,CAAC,EAC5F,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,QAAQ,CAACC,GAAG,CAAEb,aAAc,CAAE,CAAC,CACrC,CAAC,cACNQ,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,wBAAsB,CAAI,CAAC,cACpDJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,kzBAQ0C,CAAG,CAAC,EACpE,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,UAAU,CAACC,GAAG,CAAEZ,eAAgB,CAAE,CAAC,CACzC,CAAC,cACNO,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,gBAAc,CAAI,CAAC,cAC5CJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,glCAWkE,CAAG,CAAC,EAC5F,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,SAAS,CAACC,GAAG,CAAEX,cAAe,CAAE,CAAC,CACvC,CAAC,cACNM,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,mBAAiB,CAAI,CAAC,cAC/CJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,qjCAWkC,CAAG,CAAC,EAC5D,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,MAAM,CAACC,GAAG,CAAEV,WAAY,CAAE,CAAC,CACjC,CAAC,cACNK,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,aAAW,CAAI,CAAC,cACzCJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,2sCAYE,CAAG,CAAC,EAC5B,CAAC,EACH,CAAC,cAENF,KAAA,QAAKG,SAAS,CAAC,gBAAgB,CAAAD,QAAA,eAC7BJ,IAAA,QAAKK,SAAS,CAAC,UAAU,CAAAD,QAAA,cACvBJ,IAAA,QAAKM,GAAG,CAAC,OAAO,CAACC,GAAG,CAAET,YAAa,CAAE,CAAC,CACnC,CAAC,cACNI,KAAA,QAAKG,SAAS,CAAC,WAAW,CAAAD,QAAA,eACxBJ,IAAA,OAAIK,SAAS,CAAC,UAAU,CAAAD,QAAA,CAAC,WAAS,CAAI,CAAC,cACvCJ,IAAA,MAAGK,SAAS,CAAC,WAAW,CAAAD,QAAA,CAAC,0qCAWgF,CAAG,CAAC,EAC1G,CAAC,EACH,CAAC,EACH,CAAC,cAENJ,IAAA,QAAKK,SAAS,CAAC,YAAY,CAAM,CAAC,EAC/B,CAAC,CAEV,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}